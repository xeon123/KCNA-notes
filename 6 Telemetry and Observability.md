---
tags: telemetry, observability, Kubernetes, Prometheus, Grafana, monitoring
title: Telemetry and Observability
category: KCNA Notes
topics:
  - Observability
  - Telemetry
  - Logs
  - Metrics
  - Traces
  - Alerts
  - Prometheus
  - Grafana
  - Cost Management
created: 2025-03-31
updated: 2025-03-31
author: reissada
status: draft
summary: >
  This note explores telemetry and observability in cloud-native environments, focusing on logs, metrics, traces, and alerts. It also covers tools like Prometheus and Grafana, their setup, and cost management strategies for cloud-native solutions.
---

# Telemetry and observability

- **Observability** ensures accurate monitoring and efficient issue detection in cloud-native environments.
- The **three pillars**‚Äî**logs**, **metrics**, and **traces**‚Äîeach offer distinct insights into system performance and health.
  - **Logs** provide a record of events that have occurred within an application or system
  - **Metrics** offer quantitative measurements of performance and behavior
  - **Traces** allow for the visualization of complex interactions between microservices.
- **Alerts** complement these pillars by providing early warnings of potential failures, ensuring high availability and quick problem resolution.
- By analyzing these outputs, developers and operators can gain insights into how their system is behaving, identify issues, and make data-driven decisions.
- OpenTracing and OpenTelemetry primarily operate in the application layer of a software system. They provide APIs and tools for instrumenting applications to collect tracing and telemetry data, allowing developers to understand how their code behaves in production environments.

## Types of Telemetry

1. **Logs**
   - Logs are primarily used to output messages from programs, applications, and processes. These messages can include errors, warnings, debug information, or other events that occur during execution. Logs provide valuable insights into system behavior, helping developers and operators troubleshoot issues, identify trends, and optimize performance.
     - Messages generated by programs, applications, or processes.
     - Can vary in verbosity (info, debug, etc.).
     - Typically stored in files or logging systems like `syslog`.
2. **Metrics**
   - Time-based measurements collected at regular intervals.
     - By measuring metrics at set intervals (e.g., every minute), teams can understand how their systems behave under different loads, identify trends and anomalies, and make data-driven decisions.
   - Provide insights into system performance and health.
     - ¬†By analyzing historical metrics data, it is possible to identify trends and patterns that can be used to predict future resource usage. For example, if a system's CPU usage has been increasing by 10% every month for the past year, it is likely that this trend will continue into the future.
   - **Types of Metrics:**
     - **Gauges:** Point-in-time measurements (e.g., memory usage).
     - **Counters:** Cumulative values that increase over time (e.g., API requests). Often used to count the number of requests, errors, or other significant events.
     - **Meters:** Event rates over time (e.g., requests per second).
     - **Histograms:** Statistical distributions of values (e.g., response time buckets).
3. **Traces**
   - Track requests as they move through distributed systems.
   - Provide visibility into request latency, component traversal, and bottlenecks.
   - It provides a detailed, step-by-step record of how a request was handled, including any interactions with multiple services or components. This allows developers and operators to understand the flow of requests and identify potential issues.
4. **Alerts**
   - Notify teams of anomalies or failures in the system.
     - They allow developers and operators to quickly identify and respond to problems, reducing downtime and improving overall system reliability.
   - Triggered by deviations in logs, metrics, or traces to enable proactive troubleshooting.

## Prometheus and Grafana

### Enhancing Kubernetes Observability with Prometheus and Grafana

While Kubernetes provides basic insights through its CLI, true observability requires more advanced tools like **Prometheus** and **Grafana**.

Prometheus and Grafana together offer a powerful observability stack for Kubernetes, enabling better monitoring, visualization, alerting, and proactive system management. These tools are essential for roles like DevOps and SREs to meet uptime, performance, and reliability goals.

### üîç Prometheus: Monitoring & Alerting Toolkit

- **Open-source CNCF project** (second to graduate after Kubernetes), initially **created by SoundCloud**.
- Designed for monitoring and alerting in both cloud-native and traditional systems.
- **Key Features:**
  - **Multi-dimensional data model:** Uses time-series data, identified by metric names and key-value pairs.
  - **PromQL:** A flexible query language for querying time-series data.
  - **Autonomous nodes:** No need for distributed storage; each node functions independently.
  - **Push-pull data collection:** Efficient data scraping and ingestion methods.
  - **Built-in alerting:** Enables proactive issue detection.

#### üìä Grafana: Visualization & Analytics Platform

- An open-source platform that integrates with multiple data sources like **Prometheus**, **InfluxDB**, and **Elasticsearch**.
- **Core Features:**
  - **Visualization:** Customizable dashboards with graphs, charts, and alerts for easy data interpretation.
  - **Monitoring:** Tracks system performance (CPU, memory, network I/O) in real time.
  - **Alerting:** Sends notifications via email, Slack, PagerDuty, and more.
  - **Customizability:** Highly flexible dashboards and plugin support for additional functionality.

#### üîß Use Cases for Site Reliability Engineers (SREs)

- **SLAs (Service Level Agreements):** Aggrement of a vendor and a user that guarantees a certain SLO. E.g., Maintain 99.99% uptime.
- **SLOs (Service Level Objectives):** A target value of a range for an SLI. E.g., Response time under 200 ms.
- **SLIs (Service Level Indicators):** A quantitative measure of some aspect of the level of the service provided. E.g., Achieving 97% uptime with a 300 ms response time.

In the provided example, if uptime is 97% and response time exceeds 300 ms, neither SLAs nor SLOs are being met.

### Setting Up Kubernetes Observability with Helm, Prometheus, and Grafana

#### Prometheus

- Prometheus is an open-source monitoring tool that collects metrics data, and provide tools to visualize the collected data
- Prometheus allows you to generate alerts when metrics reach a user specified threshold
- Prometheus collects metrics by scraping targets who expose metrics through an HTTP endpoint
  - The role of the HTTP server is to allow the retrieval of stored metric data.
  - The role of data retrieval workers is to send HTTP requests to target and collect metrics.
- Scraped metrics are then stored in a time series database which can be queried using built-in query language PromQL
- Monitors time-series data which is numeric
- Follows a Pull-Based model that send a data to the target to pull the data.
- Advantages of a pull-based system
  - It is easy to tell if a target is down
  - There is a list of targets to monitor, creating a central source of truth.

---

##### Architecture

![[Prometheus Architecture.png]]

- Short-lived job is a program that runs for short time. The job pushes the metrics to the Pushgateway using HTTP request, which Prometheus query.
- The Pushgateway is a component in the Prometheus monitoring ecosystem that acts as a middleman for short-lived or batch jobs to expose their metrics to Prometheus.
  - The Pushgateway receives, store, and expose metrics from short-lived job.
  - Since short-lived jobs may end before a pull can occur, Pushgateway handles with this situation.
- The purpose of "Discover Targets" in Prometheus is to show which targets (endpoints) Prometheus is currently configured to scrape metrics from, and their status.
- Prometheus just trigger alerts to the AlertManager. The responsible is the AlertManager to deal with the alerts.

---

###### üîç Core Components Installed

- **Prometheus Operator (`kube-prom-operator`):** Sets up Prometheus, with a UI accessible on port `9090`.
- **Alertmanager:** Manages and handles alerts (runs as a StatefulSet).
- **Node Exporter:** Collects hardware and OS metrics that will be exposed by the kernel (deployed as a DaemonSet across all nodes).
- **Kube-State-Metrics:** Gathers metrics about Kubernetes objects like pods, nodes, and deployments.
- **Prometheus Adapter:** Converts Kubernetes metrics into Prometheus-readable metrics.
- **Grafana:** Visualizes metrics using customizable dashboards and integrates seamlessly with Prometheus.

---

##### ‚öôÔ∏è Quick Setup Using Helm & Kube-Prometheus-Stack

- The kube-prometheus operator project simplifies the deployment and configuration of Prometheus and Grafana for monitoring Kubernetes clusters. It provides a streamlined way to set up comprehensive monitoring solutions by automating many of the complex tasks involved in configuring these tools.

- **Install Helm:**
  - Update system packages and install **Git** (`apt update && apt install git`).
  - Download and install **Helm** using a curl command piped to bash.
- **Add Prometheus Helm Repo:**
  - Add the Prometheus Community repository with:

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
```

- Search for available chart versions using:

```bash
helm search repo kube-prometheus-stack -l
```

- **Install Prometheus Stack:**
  - Install a specific version (e.g., `55.5.0`) using:

```bash
helm install my-observability prometheus-community/kube-prometheus-stack --version 55.5.0
```

- Allow 10 minutes for the setup to collect meaningful metrics.

---

#### üìä Accessing Prometheus & Grafana

1. Run:

```bash
kubectl get services
```

1. Identify the Cluster IP for `my-observability-kube-prometheus-stack`.

![[Telemetry and Observability Get Service.png]]

1. Access Prometheus at:

```bash
http://<Cluster-IP>:9090
```

1. Use **kubectl port-forward** if accessing from a different environment.

`kubectl port-forward service/my-observability-kube-prom-prometheus 9090:9090`

---

#### üìà Exploring Metrics Using Prometheus UI

```yaml
<metric_name>.[{label_1="value_1",<label_N="value_N"}] <metric_value>
node_cpu_seconds_total{cpu="0",mode="idle"} 2567363
```

![[Prometheus Metrics Attributes.png]]

- Metric have the format above
  - Label provide the information on which cpu this metric is for, and the state.
  - Every metric is assigned 2 labels by default (instance and job)
    - `node_boot_in_seconds{instance="192.168.1.100:9100",job="node"}`
  - Metrics must have a TYPE and HELP attributes
    - HELP ‚Äì description of what the metric is
    - TYPE ‚Äì Specifies what type of metric(counter, gauge, histogram, summary)
- Metrics Types
  - Counter: How many times did X happen?
  - Gauge: What is the current value of X?
  - Histogram: How long something is? Groups observations into configurable bucket sizes
  - Summary: Similar to histograms. Can be percentiles, quartiles, percentages, average, etc...
- Metrics have rules:
  - Metric name specifies a general feature of a system to be measured
  - May contain ASCII letters, numbers, underscores, and colons
  - Must match the regex `[a-zA-Z_:][a-zA-Z0-9_:]*`
  - Colons are reserved only for recording rules
- The purpose of labels
  - Add context Understand what the metric actually means
  - Enable filtering Use labels in PromQL queries like method="POST"
  - Support aggregation Group by label values (e.g., sum by (status))
  - Support multi-instance metrics Distinguish between instances or pods
  - Enable dynamic service discovery Automatically attach labels like job, instance, namespace, etc.

![[Stream Time Series.png]]

- Navigate to the **Metrics Explorer**.
- Example Queries:

  - **Pod IPs:**
    ![[Telemetry and Observability Pod IPs.png]]
  - **Pods per Namespace:**
    `sum by (namespace) (kube_pod_ips)`

- Visualizations:
  - Graph views display data over time, with different lines representing different pods or namespaces.

---

##### Container Metrics

- `cmetrics` refers to **container metrics** exposed by **cAdvisor** (which is embedded in `kubelet`) in Kubernetes.
- **Docker Engine metrics** are **Prometheus-formatted performance and usage data** exposed directly by the **Docker daemon** (`dockerd`).

| Feature                 | **cmetrics (via cAdvisor / kubelet)**                                  | **Docker Engine Metrics**                                                   |
| ----------------------- | ---------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| üß© **Scope**            | Container-level metrics in **Kubernetes**                              | Container-level and daemon metrics for **Docker**                           |
| üì¶ **Typical use**      | Used in **Kubernetes environments**                                    | Used in **Docker-only environments**                                        |
| üîå **Exporter needed?** | Often exposed via **kubelet** (e.g., `/metrics/cadvisor`)              | Requires enabling **Docker metrics endpoint**                               |
| üìä **Metric examples**  | `container_cpu_usage_seconds_total` <br>`container_memory_usage_bytes` | `engine_daemon_container_cpu_seconds_total` <br>`engine_daemon_engine_info` |
| üì° **Collected by**     | Prometheus scraping kubelet or cAdvisor                                | Prometheus scraping Docker Engine's `/metrics`                              |
| üåê **Standardization**  | Uses Kubernetes and Prometheus conventions                             | Uses Docker-specific naming and format                                      |
| üîí **Security note**    | Metrics from kubelet might need proper TLS/auth                        | Docker metrics endpoint is usually localhost-only                           |

---

##### Kubernetes

- Monitor applications running on Kubernetes infrastructure
- Monitor Kubernetes Cluster
  - Control-Plane Components(api-server, coredns, kube-scheduler)
  - Kubelet(cAdvisor) ‚Äì exposing container metrics
  - Kube-state-metrics ‚Äì cluster level metrics(deployments, pod metrics)
  - Node-exporter ‚Äì Run on all nodes for host related metrics(cpu, mem, network)
- To collect the cluster-level metrics, the `kube-state-metrics` container must be deployed.
- Every node should run a `node_exporter` to expose cpu, memory, and network status
  - We can manually install the `node_exporter` on every node
  - Or configure `node_exporter` in a daemonset.
- We use Service Discovery to scrap Kube components, Node Exporters, and Kube state metrics
  - Service Discovery provides a list of targets for Prometheus to scrape
  - Exporters in monitoring setup get data from targets and convert it into Prometheus-understandable metrics.
- The Kube-Prometheus-stack chart makes use of the Prometheus Operator
  - [Prometheus Charts](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
  - A Kubernetes operator is an application-specific controller that extends the K8s API to create/configure/manage instances of complex applications(like Prometheus!)

---

#### üöÄ Running Pods & Real-Time Monitoring

- Launch multiple pods using a simple **for loop** with `kubectl run`:

  ```bash
  for i in {1..10}; do kubectl run nginx-pod-$i --image=nginx; sleep 30; done
  ```

- Adjust the graph‚Äôs time window in Prometheus UI to **5 minutes** for real-time monitoring.

---

#### üîó Advanced Monitoring with PromQL

- Explore queries like:

  ```bash
  api_server_request_total
  ```

- Provides insights into API request metrics, including scope, version, and type of requests (verbs).

### Setting Up and Managing Grafana with Prometheus for Kubernetes Monitoring

#### üö™ Accessing Grafana

1. **Get Grafana's Cluster IP:**
   - Look for the service running on **port 80**.
2. **Connect via Reverse Proxy:**
   - Enter: `http://<Cluster-IP>:80`
3. **Log in:**
   - Username: `admin`
   - Password: `prom-operator`

---

#### üìà Importing Prebuilt Dashboards for Quick Monitoring

- Speed up the setup by importing community dashboards:

  1. In Grafana, click **+ ‚Üí Import Dashboard**.
  2. Enter one of these IDs:
     - **15759**: Node Metrics Dashboard
     - **15757**: Cluster Overview Dashboard
  3. Select **Prometheus** as the data source ‚Üí Click **Import**.

- **Inspecting PromQL Queries:**

  - Open any chart ‚Üí **Inspect ‚Üí Data ‚Üí Query ‚Üí Refresh**
  - Copy and reuse the PromQL queries directly in Prometheus if needed.

---

#### üßπ Cleanup Process

1. **Uninstall Helm Deployment:**
   `helm list helm uninstall my-observability`

2. **Remove Remaining Services:**
   `kubectl get all -A kubectl delete service <service-name>`

3. **Delete NGINX Pods:**
   `kubectl delete pod nginx-pod-<id>`

## Cost Management in Cloud-Native Solutions

### üåê Key Principles of Cloud-Native Cost Management

- **Flexibility in Resource Utilization:**  
   Cloud-native applications allow you to dynamically allocate resources across public, hybrid, or private clouds based on cost, performance, or regulatory requirements.

- **Optimize Resource Usage:**
  - Regularly review resource consumption.
  - Remove or scale down unused or underutilized resources.
  - Design applications for autoscaling and flexibility to optimize resource usage.
  - Use anomaly detection and monitoring tools like KubeCost to maintain cost efficiency and security.

---

### ‚ö° Cost-Saving Strategies Across Cloud Providers

1. **On-Demand Instances:**
   - Quickly provision resources as needed.
   - **Pros:** Flexibility and speed.
   - **Cons:** Higher cost; easy to overspend if not managed properly.
2. **Reserved Instances:**
   - Commit upfront for long-term usage (weeks, months, years).
   - **Pros:** Significant cost savings for predictable workloads.
   - **Cons:** Less flexible; may need to repurpose if business needs change.
3. **Spot Instances:**
   - Bid for unused resources at a lower price.
   - **Pros:** Cost-effective for flexible, fault-tolerant applications.
   - **Cons:** No guarantee of availability; can be terminated unexpectedly.

### üìè Right-Sizing and Scaling

- **Avoid Lift-and-Shift Mistakes:**  
   Reevaluate resource needs instead of replicating on-prem configurations.
- **Autoscaling:**  
   Automatically adjusts resources to meet demand, optimizing costs dynamically.
- **Leverage Spot & On-Demand Instances:**  
   Combine these instances with autoscaling to minimize idle resource costs.

### üîç Advanced Cost Management Tools & Techniques

- **Cloud Anomaly Detection:**

- Identifies unusual resource usage patterns, potentially uncovering security issues or unexpected costs.
- Detecting cloud anomalies can help identify unexpected charges or unusual usage patterns that may indicate cost overruns or inefficiencies. By detecting these anomalies, organizations can take corrective action to optimize their cloud resources and keep costs under control.
- **KubeCost:**  
   A Kubernetes-specific tool for monitoring and managing costs. Available in both open-source and commercial versions.

## Questions

- How can you expose custom application metrics to Prometheus for tracking?
  - Utilize Prometheus client libraries
- What type of information do metrics provide about a system?
  - Information about the state of the system using numerical values.
- In the context of distributed systems, what is the purpose of a trace-id?
  - To identify and correlate log entries related to a specific request.
- Which of the following components is not part of the main Prometheus architecture?
  - Alerting system
- What are the four pieces of information typically included in metrics?
  - Metric Name, value, timestamp, and dimensions
- What is the primary purpose of an SLO (Service Level Objective) in the context of service reliability?
  - To quantify the reliability of a product to a customer.
- What is one of the key benefits of observability in dynamic environments?
  - Actionable outputs from unexpected scenarios
- Which component of Prometheus is responsible for storing the collected metrics in a time series database?
  - Time series database(TSDB)
- Which of the following statements accurately describes the purpose of logs in a system or application?
  - Logs are historical records that capture information about specific events.
- What are the essential components of a log entry in a system or application? (Select all that apply)
  - The timestamp of when the log occurred,A message containing information
-  Given the following SLI and SLO examples, what does the SLO value represent?
```ini
SLI: Latency
SLO: Latency < 100ms
```
	- The maximum allowed latency
-
